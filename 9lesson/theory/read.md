Термины из лекции, сгруппированные по темам

▎Линейная алгебра

    • Скаляр: Число или элемент поля, над которым определено векторное пространство.
    • Вектор: Одномерный массив чисел, представляющий точку в  n -мерном пространстве.
    • Матрица: Двумерный массив чисел, организованный в строки и столбцы.
    • Тензор: Многомерный массив данных.
    • Гиперплоскость: Подпространство размерности  n-1  в  n -мерном пространстве.
    • Скалярное произведение: Операция над двумя векторами, возвращающая одно число.
    • Поэлементное произведение (произведение Адамара): Операция поэлементного умножения двух векторов.
    • Внешнее произведение (тензорное произведение): Создает матрицу из двух векторов.
    • Обратная матрица: Матрица  A⁻¹ , такая что  A ⋅ A⁻¹ = I  (единичная матрица).
    • LU-разложение: Представление матрицы как произведение нижнетреугольной и верхнетреугольной матриц.

▎Статистика и вероятности

    • Вероятность: Числовая мера от 0 до 1, отражающая вероятность события.
    • Частотный и байесовский подходы: Определение вероятности через частоты событий или через степень уверенности.
    • Условная вероятность:  P(A|B)  — вероятность события  A , если произошло событие  B .
    • Теорема Байеса: Формула, связывающая условные и априорные вероятности.
    • Апостериорная вероятность: Обновленная вероятность после наблюдения факта.
    • Распределения вероятности: Нормальное, биномиальное, логнормальное и др.
    • Выборка и генеральная совокупность: Репрезентативное подмножество всех данных.
    • Бутстрэппинг и перекрестная проверка: Методы с перевыборкой для оценки моделей.
    • Смещение выборки: Искажения из-за нерепрезентативной выборки.

▎Машинное обучение

    • Регрессия: Задача предсказания вещественного значения.
    • Классификация: Задача предсказания категориальной метки.
    • Кластеризация: Группировка объектов по сходству.
    • Признаки: Столбцы матрицы входных данных, описывающие объекты.
    • Функция потерь: Мера отклонения предсказаний модели от реальных данных.
    • Гиперпараметры: Настраиваемые параметры обучения (например, скорость обучения).

▎Оптимизация

    • Градиентный спуск: Метод нахождения минимума функции.
    • Частные производные: Производные функции по одной переменной, учитывая фиксированные значения других.
    • Метод обратного распространения ошибки: Алгоритм обновления весов нейронной сети.
    • Поверхность ошибок: Трехмерное представление зависимости ошибки от параметров модели.
    • Сходимость: Процесс достижения алгоритмом оптимального решения.